# Config file for autoencoder training

dataset_params:
  nbars: 4
  im_channels : 4
  im_size : 512
  num_workers_ds : 0 # Number of workers for loading the dataset
  train_lookup_table_path: "./resources/lookup_table_train.json"
  val_lookup_table_path: "./resources/lookup_table_val.json"
  credentials_path: "./resources/key/key.json"
  bucket_name: "project-remucs-spectrograms-1"
  cache_dir: "./resources/spec_cache"
  val_count: 200 # Number of validation samples

autoencoder_params:
  z_channels: 4
  codebook_size : 8192
  down_channels : [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 32
  num_heads: 4
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  gradient_checkpointing : True

train_params:
  seed : 1943
  num_workers_dl: 0
  autoencoder_batch_size: 6 # Maximum batch size on a single A6000 GPU with 48GB VRAM
  disc_start: 4096     # Start training discriminator after this many steps. Set to a very small number for testing
  disc_weight: 0.5      # Weight of discriminator loss
  codebook_weight: 1    # Weight of codebook loss
  commitment_beta: 0.2
  perceptual_weight: 1
  epochs: 20
  autoencoder_lr: 0.00001
  autoencoder_acc_steps: 16
  autoencoder_img_save_steps: 512
  max_allowed_ckpts: 32
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'
  val_steps: 2048

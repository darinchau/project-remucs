# Config file for autoencoder training

dataset_params:
  nbars: 4
  im_channels : 4
  im_size : 512
  num_workers_ds : 0 # Number of workers for loading the dataset
  dataset_dir: "./resources/specs"
  train_lookup_table_path: "./resources/lookup_table_train.json"
  val_lookup_table_path: "./resources/lookup_table_val.json"
  credentials_path: "./resources/key.json"
  bucket_name: "project-remucs-specs"
  cache_dir: "./resources/spec_cache"
  val_count: 100 # Number of validation samples
  backup_dataset_first_n_train: 10
  backup_dataset_first_n_val: 3

autoencoder_params:
  z_channels: 4
  codebook_size : 8192
  down_channels : [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 32
  num_heads: 4
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  gradient_checkpointing : True

train_params:
  seed : 1943
  num_workers_dl: 0
  autoencoder_batch_size: 6
  disc_start: 1024     # Start training discriminator after this many steps. Set to a very small number for testing
  disc_weight: 0.5      # Weight of discriminator loss
  codebook_weight: 1    # Weight of codebook loss
  commitment_beta: 0.2
  perceptual_weight: 1
  wasserstein_regularizer: 0.1 # Regularizer for the wasserstein loss
  epochs: 2
  max_discr_to_gen_ratio: 8 # Maximum ratio of discriminator to generator steps
  autoencoder_lr: 0.00001
  autoencoder_acc_steps: 16
  autoencoder_img_save_steps: 512
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'
  run_name: "vqvae-training-6"
  mel_weight_recon_loss: False # If True, use mel filter bins to reweight the reconstruction loss
  disc_loss: "wasserstein" # "bce", "mse", or "wasserstein"
  val_steps: 512
